{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 24 hour no cutting of the remote machine\n",
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"
      ],
      "metadata": {
        "id": "AYmYOWK-eLh1"
      },
      "id": "AYmYOWK-eLh1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f59dcb-c588-41b8-a792-55d88ade739c",
      "metadata": {
        "id": "93f59dcb-c588-41b8-a792-55d88ade739c"
      },
      "outputs": [],
      "source": [
        "# Download and install ollama to the system\n",
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "id": "kCDUsBgxEuJj"
      },
      "id": "kCDUsBgxEuJj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658c147e-c7f8-490e-910e-62b80f577dda",
      "metadata": {
        "id": "658c147e-c7f8-490e-910e-62b80f577dda"
      },
      "outputs": [],
      "source": [
        "!pip install aiohttp pyngrok\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "#os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "\n",
        "async def run_process(cmd):\n",
        "  print('>>> starting', *cmd)\n",
        "  p = await asyncio.subprocess.create_subprocess_exec(\n",
        "      *cmd,\n",
        "      stdout=asyncio.subprocess.PIPE,\n",
        "      stderr=asyncio.subprocess.PIPE,\n",
        "  )\n",
        "\n",
        "  async def pipe(lines):\n",
        "    async for line in lines:\n",
        "      print(line.strip().decode('utf-8'))\n",
        "\n",
        "  await asyncio.gather(\n",
        "      pipe(p.stdout),\n",
        "      pipe(p.stderr),\n",
        "  )\n",
        "\n",
        "#register an account at ngrok.com and create an authtoken and place it here\n",
        "await asyncio.gather(\n",
        "    run_process(['ngrok', 'config', 'add-authtoken','2cPaSU0ODj3blrFBnaMgRaqW7no_7Q8J3vVAJ8QPJ5seaPhyL'])\n",
        ")\n",
        "\n",
        "await asyncio.gather(\n",
        "    run_process(['ollama', 'serve']),\n",
        "    run_process(['ngrok', 'http', '--log', 'stderr', '11434']),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n"
      ],
      "metadata": {
        "id": "tpmGLBDIFW9O"
      },
      "id": "tpmGLBDIFW9O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "sMswBb86QNu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804832c5-e059-4590-acd7-0409c5afdb0d"
      },
      "id": "sMswBb86QNu2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colab-xterm\n",
            "  Downloading colab_xterm-0.2.0-py3-none-any.whl (115 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/115.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m92.2/115.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (0.7.0)\n",
            "Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (6.3.2)\n",
            "Installing collected packages: colab-xterm\n",
            "Successfully installed colab-xterm-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A282u4fikZSg"
      },
      "id": "A282u4fikZSg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm height=500"
      ],
      "metadata": {
        "id": "gjyo5-_3Qkwc"
      },
      "id": "gjyo5-_3Qkwc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "YUTsj7B7fN8X"
      },
      "id": "YUTsj7B7fN8X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ollama.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8ip9SMDgCON",
        "outputId": "791ec36e-58fd-4c4e-ba1b-b03d9a9ec052"
      },
      "id": "U8ip9SMDgCON",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'models': [{'name': 'mistral:latest',\n",
              "   'model': 'mistral:latest',\n",
              "   'modified_at': '2024-03-05T21:22:34.332565173Z',\n",
              "   'size': 4109865159,\n",
              "   'digest': '61e88e884507ba5e06c49b40e6226884b2a16e872382c2b44a42f2d119d804a5',\n",
              "   'details': {'parent_model': '',\n",
              "    'format': 'gguf',\n",
              "    'family': 'llama',\n",
              "    'families': ['llama'],\n",
              "    'parameter_size': '7B',\n",
              "    'quantization_level': 'Q4_0'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ollama\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "6xh_HEvYR17t"
      },
      "id": "6xh_HEvYR17t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "\n",
        "stream = ollama.chat(\n",
        "    model='mistral',\n",
        "    messages=[{'role': 'user', 'content': f'summarize above :{description}'}],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "  print(chunk['message']['content'], end='', flush=True)"
      ],
      "metadata": {
        "id": "6VKiSithRMiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef9ac32-28ce-4541-d7bf-134d192039d2"
      },
      "id": "6VKiSithRMiz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the user could not find an option for a one-time payment of €5,000 on DKB's platform. They are seeking clarification on how to make such a large deposit."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Read the JSON file into a Python object\n",
        "with open('/content/smalldata.json', 'r') as file:\n",
        "    data = json.load(file)\n"
      ],
      "metadata": {
        "id": "XscPZ6H1nCvV"
      },
      "id": "XscPZ6H1nCvV",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your list of dictionaries with nested comments\n",
        "'''\n",
        "data = [\n",
        "    {\n",
        "        \"title\": \"DKB ETF Heiliger Gral Fragen\",\n",
        "        \"description\": \"Hallo,\\n\\nIch würde gerne mein ETF besparen anfangen...\",\n",
        "        \"metadata\": {\n",
        "            \"reference\": \"https://www.reddit.com/r/Finanzen/comments/1aq7ij0/dkb_etf_heiliger_gral_fragen/\",\n",
        "            \"date\": \"20240213\",\n",
        "            \"popularity\": 2\n",
        "        },\n",
        "        \"comments\": [\n",
        "            {\"number\": 1, \"content\": \"> Dieser erledigt auch alle Steuerfragen direkt selber...\"},\n",
        "            {\"number\": 2, \"content\": \"Bin auch bei der DKB aber kann deren Depot nicht empfehlen...\"},\n",
        "            # More comments...\n",
        "        ]\n",
        "    },\n",
        "    # More dictionaries...\n",
        "]\n",
        "'''\n",
        "# Extracting data from the nested structure\n",
        "list_of_dicts = [\n",
        "    {\n",
        "        'title': item['title'],\n",
        "        'description': item['description'],\n",
        "        'reference': item['metadata']['reference'],\n",
        "        'date': item['metadata']['date'],\n",
        "        'popularity': item['metadata']['popularity'],\n",
        "        # Concatenating comment number and content into a single string for each comment\n",
        "        'comments': '\\n'.join([f\"comment {comment['number']}: {comment['content']}\" for comment in item.get('comments', [])])\n",
        "    }\n",
        "    for item in data\n",
        "]\n",
        "\n",
        "# Creating a DataFrame from the extracted data\n",
        "df = pd.DataFrame(list_of_dicts)\n",
        "\n",
        "# Displaying the DataFrame\n",
        "print(df)\n",
        "df.to_csv('data.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "vlYOYoaCddUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74eef4db-0150-496a-c161-5e66ad52d665"
      },
      "id": "vlYOYoaCddUu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             title  \\\n",
            "0                     DKB ETF Heiliger Gral Fragen   \n",
            "1  ETF Sparplan für neugeborenen Neffen einrichten   \n",
            "\n",
            "                                         description  \\\n",
            "0  Hallo,\\n\\nIch würde gerne mein ETF besparen an...   \n",
            "1  Hi Community,\\nzuerst mal danke für so einige ...   \n",
            "\n",
            "                                           reference      date  popularity  \\\n",
            "0  https://www.reddit.com/r/Finanzen/comments/1aq...  20240213           2   \n",
            "1  https://www.reddit.com/r/Finanzen/comments/1ap...  20240213          14   \n",
            "\n",
            "                                            comments  \n",
            "0  comment 1: > Dieser erledigt auch alle Steuerf...  \n",
            "1  comment 1: mein tipp weil man nie weiß was pas...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert dataframe to text\n"
      ],
      "metadata": {
        "id": "hF8bya1TJW27"
      },
      "id": "hF8bya1TJW27"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert into text\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "# Get the column names\n",
        "column_names = df.columns.tolist()\n",
        "# Print the column names\n",
        "print(\"List of column names:\", column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmGpaI2fJCAB",
        "outputId": "207e41e8-4d78-4d0b-b5ac-e0e83b39cf88"
      },
      "id": "KmGpaI2fJCAB",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of column names: ['title', 'description', 'reference', 'date', 'popularity', 'comments']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ollama experiments"
      ],
      "metadata": {
        "id": "P1OhOBGVJb7I"
      },
      "id": "P1OhOBGVJb7I"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Open the text file for writing\n",
        "with open('output.txt', 'w') as file:\n",
        "    # Iterate over the rows of the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        # Write the contents of each column for the current row\n",
        "        file.write(f\"Title: {row['title']}\\n\")\n",
        "        file.write(f\"Description: {row['description']}\\n\")\n",
        "        file.write(f\"Reference: {row['reference']}\\n\")\n",
        "        file.write(f\"Date: {row['date']}\\n\")\n",
        "        file.write(f\"Popularity: {row['popularity']}\\n\")\n",
        "        file.write(f\"Comments: {row['comments']}\\n\")\n",
        "        file.write(\"\\n\") # Add a blank line between each entry for readability\n"
      ],
      "metadata": {
        "id": "W2Z04hVeJsEl"
      },
      "id": "W2Z04hVeJsEl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Iterate over each row of the DataFrame using itertuples()\n",
        "for row in df.itertuples(index=False):\n",
        "    # Use indexing to access the columns\n",
        "    filename = f\"postdate_{row[3]}_postvote{row[4]}.txt\" # Assuming 'data' is the first column and 'date' is the fourth column\n",
        "\n",
        "    # Open the text file for writing\n",
        "    with open(filename, 'w') as file:\n",
        "        # Write the contents of each column for the current row\n",
        "        file.write(f\"Title: {row[0]}\\n\") # Assuming 'title' is the first column\n",
        "        file.write(f\"Description: {row[1]}\\n\") # Assuming 'description' is the second column\n",
        "        file.write(f\"Reference: {row[2]}\\n\") # Assuming 'reference' is the third column\n",
        "        file.write(f\"Date: {row[3]}\\n\") # Assuming 'date' is the fourth column\n",
        "        file.write(f\"Popularity: {row[4]}\\n\") # Assuming 'popularity' is the fifth column\n",
        "        file.write(f\"Comments: {row[5]}\\n\") # Assuming 'comments' is the sixth column\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WNwKh9wxWbhO"
      },
      "id": "WNwKh9wxWbhO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('/content/data.csv', 'r') as csvfile, open('output.md', 'w') as mdfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        # Title section\n",
        "        mdfile.write(f\"# {row['title']}\\n\\n\")\n",
        "\n",
        "        # Description section\n",
        "        mdfile.write(f\"## Description\\n\\n{row['description']}\\n\\n\")\n",
        "\n",
        "        # Reference (URL) section\n",
        "        mdfile.write(f\"## Reference\\n\\n[Reference]({row['reference']})\\n\\n\")\n",
        "\n",
        "        # Popularity section\n",
        "        mdfile.write(f\"## Popularity\\n\\n{row['popularity']}\\n\\n\")\n",
        "\n",
        "        # Date section\n",
        "        mdfile.write(f\"## Date\\n\\n{row['date']}\\n\\n\")\n",
        "\n",
        "        # Comments section\n",
        "        comments = row['comments'].split(',') # Assuming comments are comma-separated\n",
        "        mdfile.write(\"## Comments\\n\\n\")\n",
        "        for comment in comments:\n",
        "            mdfile.write(f\"- {comment.strip()}\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZj-XX53brtS"
      },
      "id": "WZj-XX53brtS",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi md files\n",
        "import csv\n",
        "\n",
        "def process_comments(comments):\n",
        "    sections = []\n",
        "    current_section = []\n",
        "    for comment in comments:\n",
        "        if \"comment\" in comment.lower():\n",
        "            if current_section:\n",
        "                sections.append(current_section)\n",
        "                current_section = []\n",
        "        current_section.append(comment.strip())\n",
        "    if current_section:\n",
        "        sections.append(current_section)\n",
        "    return sections\n",
        "\n",
        "with open('/content/data.csv', 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        # Construct the file name using date and popularity\n",
        "        file_name = f\"date{row['date']}_popularity{row['popularity']}.md\"\n",
        "\n",
        "        with open(file_name, 'w') as mdfile:\n",
        "            # Title section\n",
        "            mdfile.write(f\"# {row['title']}\\n\\n\")\n",
        "\n",
        "            # Description section\n",
        "            mdfile.write(f\"## Description\\n\\n{row['description']}\\n\\n\")\n",
        "\n",
        "            # Reference (URL) section\n",
        "            mdfile.write(f\"## Reference\\n\\n[Reference]({row['reference']})\\n\\n\")\n",
        "\n",
        "            # Popularity section\n",
        "            mdfile.write(f\"## Popularity\\n\\n{row['popularity']}\\n\\n\")\n",
        "\n",
        "            # Date section\n",
        "            mdfile.write(f\"## Date\\n\\n{row['date']}\\n\\n\")\n",
        "\n",
        "            # Comments section\n",
        "            comments = row['comments'].split(',') # Assuming comments are comma-separated\n",
        "            comment_sections = process_comments(comments)\n",
        "            for i, section in enumerate(comment_sections, start=1):\n",
        "                mdfile.write(f\"### Comment Section {i}\\n\\n\")\n",
        "                for comment in section:\n",
        "                    mdfile.write(f\"- {comment}\\n\\n\")\n"
      ],
      "metadata": {
        "id": "7oW2QUghkPIq"
      },
      "id": "7oW2QUghkPIq",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Practicing"
      ],
      "metadata": {
        "id": "SZTWT2tssG6S"
      },
      "id": "SZTWT2tssG6S"
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "ollama.generate(model='mistral', prompt= f'Summarize {description}')"
      ],
      "metadata": {
        "id": "7VYc_07NX7dE"
      },
      "id": "7VYc_07NX7dE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = df['comments'][0]\n"
      ],
      "metadata": {
        "id": "JxxqwPVqgc3A"
      },
      "id": "JxxqwPVqgc3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Ollama\n",
        "llm = Ollama(model=\"mistral\")"
      ],
      "metadata": {
        "id": "tdiNJ8l2Vw5q"
      },
      "id": "tdiNJ8l2Vw5q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, # Adjust based on your needs\n",
        "    chunk_overlap=150, # Adjust based on your needs\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "cCrLIaYsgsrC"
      },
      "id": "cCrLIaYsgsrC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_description = text_splitter.split_text(description)"
      ],
      "metadata": {
        "id": "XY5U4ZdWgxjx"
      },
      "id": "XY5U4ZdWgxjx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = ollama.generate(model='mistral', prompt=f'Summarize in a concise clear way {split_description}')\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "Euhcys3pg1cb"
      },
      "id": "Euhcys3pg1cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ollama\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Assuming df is your DataFrame and 'description' is the column with the text to be split and used\n",
        "description = df['description'][0]\n",
        "title = df['title'][0]\n",
        "# Initialize the RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200, # Adjust based on your needs\n",
        "    chunk_overlap=15, # Adjust based on your needs\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# Apply the splitter to the description\n",
        "split_description = text_splitter.split_text(description)\n",
        "print(split_description[2])\n",
        "'''\n",
        "# Initialize an empty DataFrame to store the summaries\n",
        "output_df = pd.DataFrame(columns=['Summary'])\n",
        "\n",
        "# Iterate over each chunk, generate a summary, and append it to the output DataFrame\n",
        "for chunk in split_description:\n",
        "    print(chunk)\n",
        "    summary = ollama.generate(model='mistral', prompt=f'Summarize {chunk}')\n",
        "    output_df = output_df.append({'Summary': summary}, ignore_index=True)\n",
        "    print(output_df)\n",
        "\n",
        "# Now, output_df contains the summaries for each chunk of the description\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "H2RlG_teiHID",
        "outputId": "5b8809f7-a095-4561-bb75-1d07b61d750e"
      },
      "id": "H2RlG_teiHID",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auch alle Steuerfragen direkt selber und ich muss es in meiner Steuererklärung aufführen.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Initialize an empty DataFrame to store the summaries\\noutput_df = pd.DataFrame(columns=['Summary'])\\n\\n# Iterate over each chunk, generate a summary, and append it to the output DataFrame\\nfor chunk in split_description:\\n    print(chunk)\\n    summary = ollama.generate(model='mistral', prompt=f'Summarize {chunk}')\\n    output_df = output_df.append({'Summary': summary}, ignore_index=True)\\n    print(output_df)\\n\\n# Now, output_df contains the summaries for each chunk of the description\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "metadata": {
        "id": "UKjUPpuutjXj"
      },
      "id": "UKjUPpuutjXj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "\n",
        "stream = ollama.chat(\n",
        "    model='mistral',\n",
        "    messages=[{'role': 'user', 'content': f'summarize {split_description[2]} ?'}],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "  print(chunk['message']['content'], end='', flush=True)"
      ],
      "metadata": {
        "id": "sINZjI83kM_A"
      },
      "id": "sINZjI83kM_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream1 = ollama.generate(model='mistral', prompt= f'summarize in german: {split_description[2]}')\n",
        "stream2 =  ollama.generate(model='mistral', prompt= f'explain : {title}')"
      ],
      "metadata": {
        "id": "7oie5kO2vDS1"
      },
      "id": "7oie5kO2vDS1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stream1.response)\n",
        "print(stream2.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RnvThV_xTQo",
        "outputId": "1ade9054-184f-42b6-b7cf-b0fba263a4f2"
      },
      "id": "2RnvThV_xTQo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model': 'mistral', 'created_at': '2024-03-05T22:41:07.457375235Z', 'response': ' \"Auch alle Steuertitel selbst bearbeiten und ich muss das in meiner Steuererklärung aufverzeichnen.\"\\n\\nTranslation: I have to handle all tax topics myself and record it in my tax declaration.', 'done': True, 'context': [733, 16289, 28793, 28705, 18062, 653, 297, 319, 9358, 28747, 5370, 8477, 2349, 3807, 898, 5786, 3247, 2254, 7530, 537, 640, 15364, 290, 1349, 1037, 297, 528, 4828, 2349, 3807, 263, 4784, 2017, 969, 264, 1292, 11472, 951, 28723, 733, 28748, 16289, 28793, 345, 28741, 903, 8477, 2349, 28718, 930, 13745, 22347, 9135, 1105, 6329, 640, 15364, 290, 1349, 2846, 297, 528, 4828, 2349, 3807, 263, 4784, 2017, 969, 3021, 343, 10738, 4588, 611, 13, 13, 25825, 28747, 315, 506, 298, 4269, 544, 3947, 13817, 3561, 304, 2395, 378, 297, 586, 3947, 19827, 28723], 'total_duration': 60153298196, 'load_duration': 6826227727, 'prompt_eval_count': 44, 'prompt_eval_duration': 25167927000, 'eval_count': 52, 'eval_duration': 28158546000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = stream['response']\n",
        "print(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUGcR87TwQcW",
        "outputId": "28fd509d-8642-4f6c-c1e5-58cb068f0cf4"
      },
      "id": "TUGcR87TwQcW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"Auch alle Steuertitel selbst bearbeiten und ich muss das in meiner Steuererklärung aufverzeichnen.\"\n",
            "\n",
            "Translation: I have to handle all tax topics myself and record it in my tax declaration.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}